{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "690b8105-a04e-4f9a-801a-767d5db93f90",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# è¿›å±•æŠ¥å‘Šè‡ªåŠ¨ç”Ÿæˆ\n",
    "\n",
    "åŸºäºé¡¹ç›®æ–‡ä»¶ï¼ˆGitHubClientï¼‰è°ƒç”¨å¤§æ¨¡å‹ï¼ˆLLMï¼‰è‡ªåŠ¨ç”Ÿæˆé¡¹ç›®è¿›å±•æŠ¥å‘Šã€‚\n",
    "\n",
    "### è°ƒç”¨ OpenAI GPT å¤§æ¨¡å‹\n",
    "\n",
    "ç›¸æ¯” GitHub REST API ï¼ŒOpenAI æä¾›çš„å¤§æ¨¡å‹ç›¸å…³ API è¿­ä»£é€Ÿåº¦å¿«ï¼Œä¸”ä¸å¤Ÿç¨³å®šã€‚\n",
    "\n",
    "**GPT-4 å¾ˆéš¾èƒ½å¤Ÿå‡†ç¡®çš„ç”Ÿæˆ OpenAI Client ç›¸å…³ä»£ç **ã€‚\n",
    "\n",
    "å› æ­¤ï¼ŒGitHubSentinel é¡¹ç›®ä¸­ LLM ç›¸å…³è°ƒç”¨ä»£ç ç”±äººç±»ç¼–å†™ğŸ˜ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8f9beb-4de1-4ead-ad2d-4cc1b8692390",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Prompt ä¼˜åŒ–æµ‹è¯•\n",
    "\n",
    "åŸºäº `GithubClient` æ¨¡å—è·å–çš„ Repo æœ€æ–°è¿›å±•ï¼Œå…ˆåœ¨ ChatGPT ä¸­å°è¯•è·å–å¯ç”¨çš„æç¤ºè¯ï¼ˆPromptï¼‰æ–¹æ¡ˆã€‚\n",
    "\n",
    "-  **å®Œæ•´çš„ChatGPT å¯¹è¯è®°å½•ã€GitHubSentinel æç¤ºè¯ä¼˜åŒ–ã€‘**ï¼šhttps://chatgpt.com/share/28524ea6-2bf3-4ebe-b7d9-9c1ba5f005d2\n",
    "- ä»¥ä¸‹æµ‹è¯•ä½¿ç”¨çš„ LangChain é¡¹ç›®æ–‡ä»¶ä¸º: `./daily_progress/langchain-ai_langchain/2024-08-18.md'`\n",
    "\n",
    "\n",
    "### ChatGPTï¼ˆGPT-4ï¼‰ ç”ŸæˆæŠ¥å‘Š\n",
    "\n",
    "**Langchain-AI/Langchain Daily Progress Report - 2024-08-18**\n",
    "\n",
    "### æ–°å¢åŠŸèƒ½\n",
    "1. **Langchain æ¨¡å—æ·»åŠ **\n",
    "   - æ–°å¢äº†Langchain Boxå¥—ä»¶åŠå…¶æ–‡æ¡£åŠ è½½å™¨ (`langchain-box: add langchain box package and DocumentLoader` #25506)\n",
    "   - åŠ å…¥äº†æ–°çš„ç¤¾åŒºæä¾›è€…â€”Agentic RAG ç¤ºä¾‹ (`Community: Add Union provider - Agentic RAG example` #25509)\n",
    "   - å¼•å…¥äº†æ›´å¤šçš„å¼‚æ­¥æµ‹è¯•æ ‡å‡† (`standard-tests[patch]: async variations of all tests` #25501)\n",
    "   - å¼•å…¥äº†å¯¹å¤šç§åŒºå—é“¾çš„æ”¯æŒ (`community: add supported blockchains to Blockchain Document Loader` #25428)\n",
    "   \n",
    "2. **æ–‡æ¡£ä¸APIæ›´æ–°**\n",
    "   - æ›´æ–°äº†å¤šä¸ªé›†æˆå‚è€ƒæ–‡æ¡£å’ŒLangchainç‰ˆæœ¬çš„æ–‡æ¡£ (`docs: `integrations` reference update 9` #25511, `docs 0.3 release` #25459)\n",
    "   - å¢åŠ äº†æ–°çš„æ–‡æ¡£ç´¢å¼•å’Œæ•°æ®åŠ è½½æ–¹å¼çš„è¯´æ˜ (`[docs]: more indexing of document loaders` #25500)\n",
    "\n",
    "### ä¸»è¦æ”¹è¿›\n",
    "1. **æµ‹è¯•ä¸æ ‡å‡†åŒ–**\n",
    "   - æ·»åŠ äº†æ›´å¤šåµŒå…¥æ ‡å‡†æµ‹è¯• (`more embeddings standard tests` #25513)\n",
    "   - å¼•å…¥äº†JSONæ¨¡å¼çš„æ ‡å‡†æµ‹è¯• (`json mode standard test` #25497)\n",
    "   - æ–°å¢äº†å„ç§æ–‡æ¡£åŠ è½½å™¨çš„æ–‡æ¡£ (`[Doc] Add docs for `ZhipuAIEmbeddings`` #25467)\n",
    "\n",
    "2. **æ¡†æ¶å’Œè§„åˆ™æ”¹è¿›**\n",
    "   - å¯¹Langchainæ ¸å¿ƒæ¨¡å—è¿›è¡Œäº†Pydanticè§£æå™¨ä¿®å¤ (`langchain-core: added pydantic parser fix for issue #24995` #25516)\n",
    "   - å¢åŠ äº†B(bugbear) ruffè§„åˆ™ä»¥æé«˜ä»£ç è´¨é‡ (`core: Add B(bugbear) ruff rules` #25520)\n",
    "\n",
    "3. **é›†æˆä¸å…¼å®¹æ€§**\n",
    "   - æµ‹è¯•äº†Pydantic 2å’ŒLangchain 0.3çš„å…¼å®¹æ€§ (`openai[major] -- test with pydantic 2 and langchain 0.3` #25503)\n",
    "   - å‡†å¤‡äº†å‘Pydantic 2è¿ç§»çš„æ ¹éªŒè¯å™¨å‡çº§ (`openai[patch]: Upgrade @root_validators in preparation for pydantic 2 migration` #25491)\n",
    "\n",
    "### ä¿®å¤é—®é¢˜\n",
    "1. **é”™è¯¯ä¿®å¤**\n",
    "   - ä¿®æ­£äº†æ–‡æ¡£ä¸­çš„é”™åˆ«å­—å’Œé”™è¯¯æ¶ˆæ¯ (`docs: Fix typo in openai llm integration notebook` #25492, `docs: fix Agent deprecation msg` #25464)\n",
    "   - è§£å†³äº†ä¸åŒçš„æœç´¢æ¨¡å¼ï¼ˆå‘é‡ä¸æ–‡æœ¬ï¼‰äº§ç”Ÿä¸åŒç»“æœçš„é—®é¢˜ (`Chroma search with vector and search with text get different result using the same embedding function` #25517)\n",
    "   - ä¿®å¤äº†ä½¿ç”¨AzureSearch vectorstoreæ—¶çš„æ–‡æ¡£IDä½œä¸ºé”®çš„é—®é¢˜ (`community : [bugfix] Use document ids as keys in AzureSearch vectorstore` #25486)\n",
    "\n",
    "2. **ç³»ç»Ÿé”™è¯¯ä¸å¼‚å¸¸å¤„ç†**\n",
    "   - è§£å†³äº†åœ¨è°ƒç”¨ç‰¹å®šé“¾æ—¶ç¼ºå°‘è¾“å…¥é”®çš„é”™è¯¯ (`Raises ValueError: Missing some input keys: {'query'} everytime I invoke 'GraphCypherQAChain.from_llm' chain with query present as input keys` #25476)\n",
    "   - ä¿®æ­£äº†æœªçŸ¥ç±»å‹ 'ToolMessage' çš„ç±»å‹é”™è¯¯ (`TypeError: Got unknown type 'ToolMessage'.` #25490)\n",
    "\n",
    "---\n",
    "\n",
    "æ­¤ç®€æŠ¥è¯¦ç»†æ€»ç»“äº†Langchain AIé¡¹ç›®åœ¨2024å¹´8æœˆ18æ—¥çš„æœ€æ–°è¿›å±•ï¼ŒåŒ…æ‹¬æ–°å¢åŠŸèƒ½ã€ä¸»è¦æ”¹è¿›å’Œé—®é¢˜ä¿®å¤ï¼Œç¡®ä¿å›¢é˜Ÿæˆå‘˜äº†è§£æœ€æ–°çš„é¡¹ç›®çŠ¶æ€å’Œå³å°†åˆ°æ¥çš„æ›´æ–°ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554b5949-5982-4034-bce2-b186dedbd445",
   "metadata": {},
   "source": [
    "## å‰ç½®ä¾èµ– logger æ¨¡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45cc627-7005-4943-92cc-212f7c98f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/logger.py\n",
    "from loguru import logger\n",
    "import sys\n",
    "\n",
    "# Configure Loguru\n",
    "logger.remove()  # Remove the default logger\n",
    "logger.add(sys.stdout, level=\"DEBUG\", format=\"{time} {level} {message}\", colorize=True)\n",
    "logger.add(\"logs/app.log\", rotation=\"1 MB\", level=\"DEBUG\")\n",
    "\n",
    "# Alias the logger for easier import\n",
    "LOG = logger\n",
    "\n",
    "# Make the logger available for import with the alias\n",
    "__all__ = [\"LOG\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb11497f-35fa-4024-bff2-24d4b0b3666c",
   "metadata": {},
   "source": [
    "## LLM Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb4c8e66-41c5-4c60-9345-959f5bf935e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI  # å¯¼å…¥OpenAIåº“ç”¨äºè®¿é—®GPTæ¨¡å‹\n",
    "# from logger import LOG  # å¯¼å…¥æ—¥å¿—æ¨¡å—ï¼ˆæ¼”ç¤ºæ—¶ç›´æ¥å¯¼å…¥ï¼‰\n",
    "\n",
    "class LLM:\n",
    "    def __init__(self, model=\"gpt-3.5-turbo\"):\n",
    "        # åˆ›å»ºä¸€ä¸ªOpenAIå®¢æˆ·ç«¯å®ä¾‹\n",
    "        self.client = OpenAI(\n",
    "                base_url=\"https://api.gptsapi.net/v1\",\n",
    "                api_key=os.getenv(\"OPENAI_KEY\")\n",
    "            )\n",
    "        # ç¡®å®šä½¿ç”¨çš„æ¨¡å‹ç‰ˆæœ¬\n",
    "        self.model = model\n",
    "        # é…ç½®æ—¥å¿—æ–‡ä»¶ï¼Œå½“æ–‡ä»¶å¤§å°è¾¾åˆ°1MBæ—¶è‡ªåŠ¨è½®è½¬ï¼Œæ—¥å¿—çº§åˆ«ä¸ºDEBUG\n",
    "        LOG.add(\"daily_progress/llm_logs.log\", rotation=\"1 MB\", level=\"DEBUG\")\n",
    "\n",
    "    def generate_daily_report(self, markdown_content, dry_run=False):\n",
    "        # æ„å»ºä¸€ä¸ªç”¨äºç”ŸæˆæŠ¥å‘Šçš„æç¤ºæ–‡æœ¬ï¼Œè¦æ±‚ç”Ÿæˆçš„æŠ¥å‘ŠåŒ…å«æ–°å¢åŠŸèƒ½ã€ä¸»è¦æ”¹è¿›å’Œé—®é¢˜ä¿®å¤\n",
    "        # prompt = f\"ä»¥ä¸‹æ˜¯é¡¹ç›®çš„æœ€æ–°è¿›å±•ï¼Œæ ¹æ®åŠŸèƒ½åˆå¹¶åŒç±»é¡¹ï¼Œå½¢æˆä¸€ä»½ç®€æŠ¥ï¼Œè‡³å°‘åŒ…å«ï¼š1ï¼‰æ–°å¢åŠŸèƒ½ï¼›2ï¼‰ä¸»è¦æ”¹è¿›ï¼›3ï¼‰ä¿®å¤é—®é¢˜ï¼›:\\n\\n{markdown_content}\"\n",
    "        # system_prompt = f\"ä½ æ˜¯ä¸€ä¸ªå®šæœŸè·Ÿè¿›GitHubå¼€æºé¡¹ç›®è¿›å±•çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè´Ÿè´£è§£è¯»æœ€æ–°è¿›å±•ä¿¡æ¯ï¼Œå¹¶å½’çº³æ€»ç»“æˆä¸­æ–‡ç®€æŠ¥ã€‚\\n\\nä½ å°†æ”¶åˆ°ç”±issueså’Œpull requestsç»„æˆçš„æœ€æ–°è¿›å±•ä¿¡æ¯ï¼Œè¯·åˆ†æè§£è¯»åç”Ÿæˆä¸€ä»½è¿›å±•ç®€æŠ¥ï¼Œæ¶µç›–ä»¥ä¸‹å†…å®¹ï¼š\\n\\n1.æ¦‚æ‹¬æ€»ç»“é¡¹ç›®å½“å‰é‡ç‚¹è¿›å±•æƒ…å†µã€‚ä»…é’ˆå¯¹æä¾›çš„ä¿¡æ¯æ€»ç»“ï¼Œé¿å…å¥—è¯ã€‚\\n\\n2.æ ¹æ®æ–°å¢åŠŸèƒ½ã€ä¿®å¤é—®é¢˜ã€ä¼˜åŒ–æ”¹è¿›æ•´ç†å’Œåˆå¹¶ç›¸ä¼¼çš„issueå’Œpull requestã€‚è¦æ±‚æ•´ç†ç»“æœé€æ¡å±•ç¤ºï¼Œå¹¶åœ¨æ¯æ¡æœ€åä¿ç•™issueæˆ–PRçš„numberå·ã€‚\"\n",
    "        system_prompt = f\"ä½ æ˜¯ä¸€ä¸ªå–„äºæ€»ç»“GitHubå¼€æºé¡¹ç›®è¿›å±•çš„ä¸­æ–‡æ™ºèƒ½åŠ©æ‰‹ã€‚\\n\\nä½ å°†æ”¶åˆ°ç”±issueså’Œpull requestsç»„æˆçš„è¯¦ç»†è¿›å±•ä¿¡æ¯ï¼Œè¯·ä½ åˆ†æå’Œè§£è¯»åï¼Œå½’çº³æ€»ç»“æˆä¸€ä»½ä¸­æ–‡ç®€æŠ¥ï¼Œæ¶µç›–ä»¥ä¸‹3ç±»å†…å®¹ï¼š1.æ–°å¢åŠŸèƒ½ï¼›2.ä¿®å¤é—®é¢˜ï¼›3.ä¼˜åŒ–æ”¹è¿›ã€‚\\n\\nç®€æŠ¥å†…å®¹ä¸¥æ ¼ä¿æŒmarkdownæ ¼å¼ï¼ŒåŠ¡å¿…ä½¿ç”¨ä¸­æ–‡æ€»ç»“ã€‚æ¯ä¸ªç±»åˆ«çš„è¿›å±•é€æ¡å±•ç¤ºï¼Œæ¯æ¡è¿›å±•æœ€åä¿ç•™issueæˆ–PRçš„numberå·ã€‚\\n\\nè¦æ±‚æ•´ç†å’Œåˆå¹¶ç›¸ä¼¼çš„issueå’Œpull requestï¼Œç›¸åŒçš„numberå·ä»…éœ€è¦åœ¨ä¸€ä¸ªç±»åˆ«é‡Œã€‚\\n\\n\"\n",
    "        user_prompt = f\"{markdown_content}\"\n",
    "        if dry_run:\n",
    "            # å¦‚æœå¯ç”¨äº†dry_runæ¨¡å¼ï¼Œå°†ä¸ä¼šè°ƒç”¨æ¨¡å‹ï¼Œè€Œæ˜¯å°†æç¤ºä¿¡æ¯ä¿å­˜åˆ°æ–‡ä»¶ä¸­\n",
    "            LOG.info(\"Dry run mode enabled. Saving prompt to file.\")\n",
    "            with open(\"daily_progress/prompt.txt\", \"w+\") as f:\n",
    "                f.write(system_prompt)\n",
    "                f.write(\"\\n\\n\")\n",
    "                f.write(user_prompt)\n",
    "            LOG.debug(\"Prompt saved to daily_progress/prompt.txt\")\n",
    "            return \"DRY RUN\"\n",
    "\n",
    "        # æ—¥å¿—è®°å½•å¼€å§‹ç”ŸæˆæŠ¥å‘Š\n",
    "        LOG.info(f\"Starting report generation using model: {self.model}.\")\n",
    "        \n",
    "        try:\n",
    "            # è°ƒç”¨OpenAI GPTæ¨¡å‹ç”ŸæˆæŠ¥å‘Š\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,  # æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹ç‰ˆæœ¬\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}  # æäº¤ç”¨æˆ·è§’è‰²çš„æ¶ˆæ¯\n",
    "                ]\n",
    "            )\n",
    "            LOG.debug(f\"{self.model} response: {response}\")\n",
    "            # è¿”å›æ¨¡å‹ç”Ÿæˆçš„å†…å®¹\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            # å¦‚æœåœ¨è¯·æ±‚è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸ï¼Œè®°å½•é”™è¯¯å¹¶æŠ›å‡º\n",
    "            LOG.error(\"An error occurred while generating the report: {}\", e)\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d2f6d-d2a5-4524-be4f-7e94c53f07e7",
   "metadata": {},
   "source": [
    "## ReportGenerator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652363c5-b211-48a9-93ae-54268e7ee13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/report_generator.py\n",
    "\n",
    "import os\n",
    "from datetime import date, timedelta\n",
    "# from logger import LOG  # å¯¼å…¥æ—¥å¿—æ¨¡å—ï¼Œç”¨äºè®°å½•æ—¥å¿—ä¿¡æ¯\n",
    "\n",
    "class ReportGenerator:\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm  # åˆå§‹åŒ–æ—¶æ¥å—ä¸€ä¸ªLLMå®ä¾‹ï¼Œç”¨äºåç»­ç”ŸæˆæŠ¥å‘Š\n",
    "\n",
    "    def export_daily_progress(self, repo, updates):\n",
    "        # æ„å»ºä»“åº“çš„æ—¥å¿—æ–‡ä»¶ç›®å½•\n",
    "        repo_dir = os.path.join('daily_progress', repo.replace(\"/\", \"_\"))\n",
    "        os.makedirs(repo_dir, exist_ok=True)  # å¦‚æœç›®å½•ä¸å­˜åœ¨åˆ™åˆ›å»º\n",
    "        \n",
    "        # åˆ›å»ºå¹¶å†™å…¥æ—¥å¸¸è¿›å±•çš„Markdownæ–‡ä»¶\n",
    "        file_path = os.path.join(repo_dir, f'{date.today()}.md')\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(f\"# Daily Progress for {repo} ({date.today()})\\n\\n\")\n",
    "            file.write(\"\\n## Issues\\n\")\n",
    "            for issue in updates['issues']:\n",
    "                file.write(f\"- {issue['title']} #{issue['number']}\\n\")\n",
    "            file.write(\"\\n## Pull Requests\\n\")\n",
    "            for pr in updates['pull_requests']:\n",
    "                file.write(f\"- {pr['title']} #{pr['number']}\\n\")\n",
    "        return file_path\n",
    "\n",
    "    def export_progress_by_date_range(self, repo, updates, days):\n",
    "        # æ„å»ºç›®å½•å¹¶å†™å…¥ç‰¹å®šæ—¥æœŸèŒƒå›´çš„è¿›å±•Markdownæ–‡ä»¶\n",
    "        repo_dir = os.path.join('daily_progress', repo.replace(\"/\", \"_\"))\n",
    "        os.makedirs(repo_dir, exist_ok=True)\n",
    "\n",
    "        today = date.today()\n",
    "        since = today - timedelta(days=days)  # è®¡ç®—èµ·å§‹æ—¥æœŸ\n",
    "        \n",
    "        date_str = f\"{since}_to_{today}\"  # æ ¼å¼åŒ–æ—¥æœŸèŒƒå›´å­—ç¬¦ä¸²\n",
    "        file_path = os.path.join(repo_dir, f'{date_str}.md')\n",
    "        \n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(f\"# Progress for {repo} ({since} to {today})\\n\\n\")\n",
    "            file.write(\"\\n## Issues Closed in the Last {days} Days\\n\")\n",
    "            for issue in updates['issues']:\n",
    "                file.write(f\"- {issue['title']} #{issue['number']}\\n\")\n",
    "            file.write(\"\\n## Pull Requests Merged in the Last {days} Days\\n\")\n",
    "            for pr in updates['pull_requests']:\n",
    "                file.write(f\"- {pr['title']} #{pr['number']}\\n\")\n",
    "        \n",
    "        LOG.info(f\"Exported time-range progress to {file_path}\")  # è®°å½•å¯¼å‡ºæ—¥å¿—\n",
    "        return file_path\n",
    "\n",
    "    def generate_daily_report(self, markdown_file_path):\n",
    "        # è¯»å–Markdownæ–‡ä»¶å¹¶ä½¿ç”¨LLMç”Ÿæˆæ—¥æŠ¥\n",
    "        with open(markdown_file_path, 'r') as file:\n",
    "            markdown_content = file.read()\n",
    "\n",
    "        report = self.llm.generate_daily_report(markdown_content, False)  # è°ƒç”¨LLMç”ŸæˆæŠ¥å‘Š\n",
    "\n",
    "        report_file_path = os.path.splitext(markdown_file_path)[0] + \"_report.md\"\n",
    "        with open(report_file_path, 'w+') as report_file:\n",
    "            report_file.write(report)  # å†™å…¥ç”Ÿæˆçš„æŠ¥å‘Š\n",
    "\n",
    "        LOG.info(f\"Generated report saved to {report_file_path}\")  # è®°å½•ç”ŸæˆæŠ¥å‘Šæ—¥å¿—\n",
    "\n",
    "    def generate_report_by_date_range(self, markdown_file_path, days):\n",
    "        # ç”Ÿæˆç‰¹å®šæ—¥æœŸèŒƒå›´çš„æŠ¥å‘Šï¼Œæµç¨‹ä¸æ—¥æŠ¥ç”Ÿæˆç±»ä¼¼\n",
    "        with open(markdown_file_path, 'r') as file:\n",
    "            markdown_content = file.read()\n",
    "\n",
    "        report = self.llm.generate_daily_report(markdown_content)\n",
    "\n",
    "        report_file_path = os.path.splitext(markdown_file_path)[0] + f\"_report.md\"\n",
    "        with open(report_file_path, 'w+') as report_file:\n",
    "            report_file.write(report)\n",
    "\n",
    "        LOG.info(f\"Generated report saved to {report_file_path}\")  # è®°å½•ç”ŸæˆæŠ¥å‘Šæ—¥å¿—\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08d32e6-93d4-4593-a54a-51b8dffbc0e2",
   "metadata": {},
   "source": [
    "## è°ƒç”¨ GPT-3.5-Turbo API ç”ŸæˆæŠ¥å‘Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "577d50a5-daf4-4d7d-adf4-6932af517037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®ä¾‹åŒ– LLMï¼Œå¹¶ä½¿ç”¨é»˜è®¤çš„ GPT-3.5-Turbo æ¨¡å‹\n",
    "llm = LLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06114d2e-8a32-48f9-bcb8-4bb8e5460f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®ä¾‹åŒ– ReportGenerator\n",
    "report_generator = ReportGenerator(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb2b520-6a2f-4898-94cc-55e85d58fc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-28T02:29:48.264230-0700 INFO Starting report generation using model: gpt-3.5-turbo.\n",
      "2024-08-28T02:29:56.281217-0700 DEBUG gpt-3.5-turbo response: ChatCompletion(id='chatcmpl-A19HpikkPwNarGhNnOYtbc2uY9T61', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='# langchain-ai/langchain Daily Progress - 2024-08-28\\n\\n## æ–°å¢åŠŸèƒ½\\n- å¼•å…¥Amazon OpenSearch Serverless (aoss)ä½œä¸ºè¯­ä¹‰ç¼“å­˜å‚¨å­˜é€‰é¡¹ #25797\\n- æ–°å¢Constrained COTè¯„ä¼°å™¨ #25796\\n- æ–°å¢SQLè®°å½•ç®¡ç†å™¨ #25795\\n- æ–°å¢UnstructuredFileLoaderæ”¯æŒpdfæ ¼å¼ #25774\\n- å¢åŠ TablestoreVectorStore #25767\\n- æ–°å¢Apache Opendal S3æ–‡æ¡£åŠ è½½å™¨ #25734\\n- æ”¯æŒåœ¨Elastic Searchå®¹å™¨ä¸­å­˜å‚¨çš„DenseXåµŒå…¥ #25744\\n- æ–°å¢ gaode weather query tool #25654\\n\\n## ä¿®å¤é—®é¢˜\\n- ä¿®å¤å‘é‡å­˜å‚¨å™¨ QdrantVectorStore ç±»å‹çš„è‡ªæŸ¥è¯¢æ£€ç´¢é—®é¢˜ #25798\\n- ä¿®å¤ bug #25793\\n- ä¿®å¤zep_couldå­˜å‚¨ç©ºé—´çš„å†…å­˜é”™è¯¯ #25791\\n- ä¿®å¤ Moderation Chain ä¸­çš„ B/Cé—®é¢˜ #25778\\n- ä¿®å¤chatæ¨¡å‹å¯åŠ¨å‚æ•°é»˜è®¤å€¼å’Œä¸€äº›ä½¿ç”¨model providerçš„é—®é¢˜ #25731\\n- ä¿®å¤deepinfraçš„æ¨¡å‹åˆå§‹åŒ–bug #25727\\n\\n## ä¼˜åŒ–æ”¹è¿›\\n- ä¿®æ”¹communityï¼šé¿å…â€œlangchain_promptyâ€ä¸­çš„åŒé‡æ¨¡æ¿ #25777\\n- ä½¿PineconeHybridSearchRetrieveræ”¯æŒè¯„åˆ† #25781\\n- TextLoaderæ”¯æŒtry exceptæ•è·å¼‚å¸¸ #25768\\n- æ”¹è¿›multi-element rich textçš„å¤„ç† #25762\\n- ä½¿embedding dimensionæ£€æŸ¥å¯é€‰ #25737\\n- å¼‚æ­¥æ”¯æŒredis chatæ¶ˆæ¯å†å²è®°å½• #25732\\n- æ”¹è¿›extract hyperlinks å·¥å…·è¾“å‡º #25728\\n- æä¾›è¯­éŸ³ç¼“å­˜ç”¨äºanthropic #25684\\n- æ”¯æŒåœ¨UCFunctionToolkitä¸­æ‰§è¡Œå‡½æ•°çš„ä¼ é€’é¢å¤–å‚æ•° #25652\\n\\næ³¨ï¼šä»¥ä¸Šæ˜¯ langchain-ai/langchain é¡¹ç›®åœ¨ 2024 å¹´ 8 æœˆ 28 æ—¥çš„æ–°å¢åŠŸèƒ½ã€ä¿®å¤é—®é¢˜å’Œæ”¹è¿›ä¼˜åŒ–è¿›å±•ã€‚', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1724837389, model='gpt-35-turbo', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=485, prompt_tokens=1152, total_tokens=1637))\n",
      "2024-08-28T02:29:56.283290-0700 INFO Generated report saved to daily_progress/langchain-ai_langchain_2024-08-28_report.md\n"
     ]
    }
   ],
   "source": [
    "# ç”Ÿæˆ LangChain é¡¹ç›®æœ€è¿‘ä¸€æ—¥æŠ¥å‘Š\n",
    "report_generator.generate_daily_report(\n",
    "    markdown_file_path=\"daily_progress/langchain-ai_langchain_2024-08-28.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa6d7c4-56c2-42f7-afc6-0b166e634ced",
   "metadata": {},
   "source": [
    "## è°ƒç”¨ GPT-4-Turbo API ç”ŸæˆæŠ¥å‘Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49620292-834f-465d-8ba5-e3bbf0045ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®ä¾‹åŒ– LLMï¼Œå¹¶ä½¿ç”¨æŒ‡å®šçš„ GPT-4-Turbo æ¨¡å‹\n",
    "gpt_4 = LLM(model=\"gpt-4-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12429122-8bde-406f-9b9f-ec671871ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®ä¾‹åŒ– ReportGenerator, å¹¶ä½¿ç”¨æŒ‡å®šçš„ GPT-4-Turbo æ¨¡å‹\n",
    "rg_gpt_4 = ReportGenerator(gpt_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aff72bc-9324-4553-9fb9-5948b8715cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-28T02:31:09.577023-0700 INFO Starting report generation using model: gpt-4-turbo.\n",
      "2024-08-28T02:31:44.002469-0700 DEBUG gpt-4-turbo response: ChatCompletion(id='chatcmpl-A19J8JTPKFZA3e1e8lhjYRWZ7W277', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"### æ–°å¢åŠŸèƒ½\\n- æ–°å¢æ”¯æŒè‡ªå®šä¹‰æŸ¥è¯¢æ£€ç´¢å™¨ `VectorStore` ç±»å‹ä¸º `langchain_qdrant.qdrant.QdrantVectorStore` çš„åŠŸèƒ½ã€‚ #25798\\n- æ–°å¢ä½¿ç”¨ Amazon OpenSearch Serverless (AOSS) ä½œä¸ºè¯­ä¹‰ç¼“å­˜å­˜å‚¨åŠŸèƒ½ã€‚å‚ä¸è€…ï¼šIssues & PR #25797\\n- æ–°å¢â€œå—é™COTè¯„ä¼°å™¨â€è¯„ä¼°åŠŸèƒ½ã€‚å‚ä¸è€…ï¼šIssues & PR #25796\\n- æ–°å¢ SQL è®°å½•ç®¡ç†å™¨ã€‚å‚ä¸è€…ï¼šIssues #25795\\n- æ–°å¢ PDF æ–‡ä»¶æ”¯æŒçš„æ— ç»“æ„æ–‡ä»¶åŠ è½½å™¨ã€‚ #25774\\n- æ–°å¢å¯¹ `OpenLLM` å¢åŠ æœ¬åœ°æœåŠ¡å™¨è¿æ¥çš„æ”¯æŒï¼Œè§£å†³äº†æ— å±æ€§ 'client' çš„é”™è¯¯ã€‚ #25772\\n- æ–°å¢ `TablestoreVectorStore` ä¸ºå­˜å‚¨åº“å¢åŠ è¡¨å­˜å‚¨çš„æ”¯æŒã€‚å‚ä¸è€…ï¼šIssues & PR #25767\\n- æ–°å¢å¯¹ `Apache Opendal S3 document loader` æ–‡æ¡£åŠ è½½å™¨çš„æ”¯æŒï¼Œå¢å¼ºäº‘å­˜å‚¨æ–‡ä»¶å¤„ç†åŠŸèƒ½ã€‚å‚ä¸è€…ï¼šIssues & PR #25734\\n- æ–°å¢å¤šå…ƒç´ å¯Œæ–‡æœ¬çš„æ­£ç¡®å¤„ç†æ”¯æŒã€‚å‚ä¸è€…ï¼šIssues & PR #25762\\n- æ–°å¢å¯¹ DenseX Embeddings åœ¨ Elasticsearch å®¹å™¨ä¸­çš„å­˜å‚¨æ”¯æŒã€‚ #25744\\n- æ–°å¢å¯¹ Neo4j å‘é‡åµŒå…¥çš„ç»´åº¦æ£€æŸ¥å¯é€‰æ”¯æŒã€‚å‚ä¸è€…ï¼šIssues & PR #25737\\n- æ–°å¢å¼‚æ­¥æ”¯æŒRedisèŠå¤©ä¿¡æ¯å†å²ã€‚å‚ä¸è€…ï¼šIssues & PR #25732\\n- æ–°å¢ MongoDB èŠå¤©ä¿¡æ¯å†å²ç°æœ‰ mongo_client çš„æ”¯æŒã€‚ #25726\\n- æ–°å¢æ”¯æŒå‘ UCFunctionToolkit æ‰§è¡ŒåŠŸèƒ½æ—¶ä¼ é€’é¢å¤–å‚æ•°çš„åŠŸèƒ½ã€‚ #25652\\n- æ–°å¢æ”¯æŒè°ƒç”¨å·¥å…·æ—¶æ”¯æŒ Ollama Model çš„åŠŸèƒ½ã€‚ #25681\\n\\n### ä¿®å¤é—®é¢˜\\n- ä¿®å¤ bug å‘ç°åŠå…¶ä¿®å¤ã€‚å‚ä¸è€…ï¼šIssues & PR #25793\\n- ä¿®å¤æ¢å¤é“¾ä¸­çš„æ­£åå‘å…¼å®¹é—®é¢˜ã€‚å‚ä¸è€…ï¼šIssues & PR #25778\\n- ä¿®å¤æ— æ³•ä½¿ç”¨ try except çš„ TextLoader é—®é¢˜ã€‚ #25768\\n- ä¿®å¤å¤šæ¨¡å‹åˆå§‹åŒ– bugï¼Œå½±å“æ·±åº¦åŸºç¡€è®¾æ–½éƒ¨ç½²ã€‚å‚ä¸è€…ï¼šIssues & PR #25727\\n- ä¿®å¤ index api å½“ batch_size < n_docs æ—¶çš„é—®é¢˜ã€‚å‚ä¸è€…ï¼šIssues & PR #25754\\n- ä¿®å¤é…ç½®é»˜è®¤æ¨¡å‹å‚æ•°æ—¶é˜»æ­¢ä½¿ç”¨ç‰¹å®šæ¨¡å‹æä¾›è€…çš„é—®é¢˜ã€‚ #25731\\n- ä¿®å¤æç¤ºå˜é‡é”™è¯¯ä¿¡æ¯çš„é—®é¢˜ã€‚å‚ä¸è€…ï¼šIssues & PR #25787\\n\\n### ä¼˜åŒ–æ”¹è¿›\\n- ä¼˜åŒ–è¯„ä¼°æ¨¡å—æ–°æ·»åŠ çš„å—é™COTè¯„ä¼°å™¨ã€‚å‚ä¸è€…ï¼šIssues & PR #25796\\n- ä¼˜åŒ–æ–‡æ¡£ï¼Œé’ˆå¯¹ Vertex Embeddings Models å’Œ GraphVectorStore è¿›è¡Œäº†æ›´æ–°ã€‚å‚ä¸è€…ï¼šIssues #25745, #25751\\n- ä¼˜åŒ– `langchain_prompty` é¿å…åŒå±‚æ¨¡æ¿å¤„ç†ã€‚å‚ä¸è€…ï¼šIssues & PR #25777\\n- ä¼˜åŒ– PineconeHybridSearchRetriever æ·»åŠ è¯„åˆ†åŠŸèƒ½ã€‚å‚ä¸è€…ï¼šIssues & PR #25781\\n- ä¼˜åŒ–æ–‡æ¡£æ•´ä½“ç»“æ„ï¼Œæ›´æ–°äº† `integrations` å‚è€ƒæ–‡æ¡£ã€‚ #25711, #25676\\n- ä¼˜åŒ–å¯¹è¯æ¨¡æ¿æ”¯æŒå­—å…¸æ ¼å¼ã€‚ #25674\\n- ä¼˜åŒ–å·¥å…·æ¨¡å—ï¼ŒåŠ å…¥é«˜å¾·å¤©æ°”æŸ¥è¯¢å·¥å…·ã€‚ #25654\\n- ä¼˜åŒ–äº†è¶…é“¾æ¥æå–å·¥å…·çš„è¾“å‡ºã€‚å‚ä¸è€…ï¼šIssues & PR #25728\\n- ä¼˜åŒ– StructuredPrompt æ”¯æŒé¢å¤–çš„å…³é”®è¯å‚æ•°ã€‚ #25645\\n- ä¼˜åŒ– RunnableWithMessageHistory å¢åŠ é¢å¤–è¾“å…¥å‚æ•°ã€‚å‚ä¸è€…ï¼šIssues & PR #25756\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1724837470, model='gpt-4-turbo-2024-04-09', object='chat.completion', service_tier=None, system_fingerprint='fp_6f7679d977', usage=CompletionUsage(completion_tokens=944, prompt_tokens=1150, total_tokens=2094))\n",
      "2024-08-28T02:31:44.003518-0700 INFO Generated report saved to daily_progress/langchain-ai_langchain_2024-08-28_report.md\n"
     ]
    }
   ],
   "source": [
    "# ç”Ÿæˆ LangChain é¡¹ç›®æœ€è¿‘ä¸€æ—¥æŠ¥å‘Š\n",
    "rg_gpt_4.generate_daily_report(\n",
    "    markdown_file_path=\"daily_progress/langchain-ai_langchain_2024-08-28.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7492030c-449b-4d57-9503-4a18fa669438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2cfd8-1945-4870-b2db-f53f7e408144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cae5aea5-7df9-4c0d-97a8-1d80cef0cf0f",
   "metadata": {},
   "source": [
    "### Homework: ä¸ChatGPTæ·±åº¦å¯¹è¯ï¼Œå°è¯•ä½¿ç”¨ System role æå‡æŠ¥å‘Šè´¨é‡å’Œç¨³å®šæ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb42712-590f-45fc-b156-e902a3745e78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
